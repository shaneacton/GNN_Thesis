{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import stanfordnlp\n",
    "# import neuralcoref\n",
    "from nltk import pos_tag, ne_chunk\n",
    "\n",
    "\n",
    "from Code.Data.text import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: the apple is bad . super bad . i even thought it was ok . my name is edmandolo\n",
      "tokens: ['the', 'apple', 'is', 'bad', '.', 'super', 'bad', '.', 'i', 'even', 'thought', 'it', 'was', 'ok', '.', 'my', 'name', 'is', 'edmandolo']\n",
      "subtoken map: [['the'], ['apple'], ['is'], ['bad'], ['.'], ['super'], ['bad'], ['.'], ['i'], ['even'], ['thought'], ['it'], ['was'], ['ok'], ['.'], ['my'], ['name'], ['is'], ['ed', '##man', '##do', '##lo']]\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"the apple is bad. super bad. I even thought it was ok. My  name is Edmandolo\" * 1\n",
    "text = Text(raw_text)\n",
    "\n",
    "print(\"clean:\",text.clean)\n",
    "print(\"tokens:\", text.token_sequence.tokens)\n",
    "print(\"subtoken map:\", text.token_sequence.sub_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk pos: [('the', 'DT'), ('apple', 'NN'), ('is', 'VBZ'), ('bad', 'JJ'), ('.', '.'), ('super', 'JJ'), ('bad', 'JJ'), ('.', '.'), ('i', 'VB'), ('even', 'RB'), ('thought', 'VBD'), ('it', 'PRP'), ('was', 'VBD'), ('ok', 'RB'), ('.', '.'), ('my', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('edmandolo', 'JJ')]\n",
      "nlkt NER: (S\n",
      "  the/DT\n",
      "  apple/NN\n",
      "  is/VBZ\n",
      "  bad/JJ\n",
      "  ./.\n",
      "  super/JJ\n",
      "  bad/JJ\n",
      "  ./.\n",
      "  i/VB\n",
      "  even/RB\n",
      "  thought/VBD\n",
      "  it/PRP\n",
      "  was/VBD\n",
      "  ok/RB\n",
      "  ./.\n",
      "  my/PRP$\n",
      "  name/NN\n",
      "  is/VBZ\n",
      "  edmandolo/JJ)\n"
     ]
    }
   ],
   "source": [
    "print(\"nltk pos:\",pos_tag(text.token_sequence.tokens))\n",
    "print(\"nlkt NER:\",ne_chunk(pos_tag(text.token_sequence.tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/shane/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/shane/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/shane/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/shane/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "word: <Word index=1;text=the;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art> pos: DT\n",
      "word: <Word index=2;text=apple;lemma=apple;upos=PROPN;xpos=NNP;feats=Number=Sing> pos: NNP\n",
      "word: <Word index=3;text=is;lemma=be;upos=AUX;xpos=VBZ;feats=Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin> pos: VBZ\n",
      "word: <Word index=4;text=bad;lemma=bad;upos=ADJ;xpos=JJ;feats=Degree=Pos> pos: JJ\n",
      "word: <Word index=5;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_> pos: .\n",
      "word: <Word index=1;text=super;lemma=super;upos=ADV;xpos=RB;feats=_> pos: RB\n",
      "word: <Word index=2;text=bad;lemma=bad;upos=ADJ;xpos=JJ;feats=Degree=Pos> pos: JJ\n",
      "word: <Word index=3;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_> pos: .\n",
      "word: <Word index=1;text=i;lemma=i;upos=PRON;xpos=PRP;feats=Case=Nom|Number=Sing|Person=1|PronType=Prs> pos: PRP\n",
      "word: <Word index=2;text=even;lemma=even;upos=ADV;xpos=RB;feats=_> pos: RB\n",
      "word: <Word index=3;text=thought;lemma=think;upos=VERB;xpos=VBD;feats=Mood=Ind|Tense=Past|VerbForm=Fin> pos: VBD\n",
      "word: <Word index=4;text=it;lemma=it;upos=PRON;xpos=PRP;feats=Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs> pos: PRP\n",
      "word: <Word index=5;text=was;lemma=be;upos=AUX;xpos=VBD;feats=Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin> pos: VBD\n",
      "word: <Word index=6;text=ok;lemma=ok;upos=ADJ;xpos=JJ;feats=Degree=Pos> pos: JJ\n",
      "word: <Word index=7;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_> pos: .\n",
      "word: <Word index=8;text=my;lemma=my;upos=PRON;xpos=PRP$;feats=Number=Sing|Person=1|Poss=Yes|PronType=Prs> pos: PRP$\n",
      "word: <Word index=9;text=name;lemma=name;upos=NOUN;xpos=NN;feats=Number=Sing> pos: NN\n",
      "word: <Word index=10;text=is;lemma=be;upos=AUX;xpos=VBZ;feats=Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin> pos: VBZ\n",
      "word: <Word index=11;text=edmandolo;lemma=edmandolo;upos=ADJ;xpos=JJ;feats=Degree=Pos> pos: JJ\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(processors=\"tokenize,mwt,lemma,pos\")\n",
    "doc = nlp(text.clean)\n",
    "\n",
    "doc.sentences[0].print_dependencies()\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(\"word:\",word,\"pos:\",word.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:\n",
      "European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\n",
      "[('European', 'NORP'), ('Google', 'ORG'), ('$5.1 billion', 'MONEY'), ('Wednesday', 'DATE')]\n",
      "\n",
      "clean text:\n",
      "european authorities fined google a record $ 5 . 1 billion on wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\n",
      "[('a record $ 5', 'MONEY'), ('1 billion', 'CARDINAL'), ('wednesday', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "ent_test_text = Text('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "doc = nlp(ent_test_text.text)\n",
    "print(\"text:\\n\", ent_test_text, sep=\"\")\n",
    "print([(X.text, X.label_) for X in doc.ents])\n",
    "doc = nlp(ent_test_text.clean)\n",
    "print(\"\\nclean text:\\n\", ent_test_text.clean, sep=\"\")\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
