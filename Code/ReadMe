Todo:
* change graph encoding to inherit Batch instead of Data
* bug in graph construction - word to token not getting every link


* Graph embedder
     * query aware embeddings
     * relative positional encodings
        * fix level/source confusion

     * make fine tuning the contextual embedder optional
     * edge feature encodings. an embedder for subtype info
     * more sophisticated attentive summarisation, possibly utilising sliding window att to pretransform a sequence
        before using self attentive pooling

* Graph construction
     * add support for candidate entity nodes
     * node filters to allow for word nodes be filtered by query words
     * swap out spacy coref for something better
     * AMR
     * decouple with spacy tokens
     * make type a param not class type. when special classes are created - they pass a rep of their class type to type
        * this allows for generic edges and nodes which can still be given distinct types/subtypes

* GNNs
    * wire up the new module system to be configurable
        * should be able to use multiple message modules
        * activations and regularisers
    * create output models
        * candidate selection
        * span prediction
    * bake in residual connections transformer style
    * make generic hierarchical layer switching module
        * basic is layer dependants + 1 layer agnostic
        * can be reused for task switching later

* config summary graphs for visualisation
    * graph construction summary graphs
        * can include embedding information
    * gnn layer switching summary graphs
    * gnn summary graph which doesn't include switching info. just layers, types, sizes. like cdn diagram
     * make fine tuning the contextual embedder optional

* render sparse adjacency matrices


* Make bert tokeniser cased
* add in returning edges for the directed edges

NLP Libs:
Spacy - ineffective
StanfordNLP python wrapper has no coref

