Todo:

* General:
    * add option to use query-coattention on the entity and candidate embeddings
    * add dropout to output model and other


* Transformers
    * check that a transformer is an adequate substitute for coattention
    * try add query tokens to summariser sequences
    * more batching can be done in the summariser
    * code reuse between switch and regular variants

* GNNs
    * switch additive attention for dot-product
    * directionality


* Graph structuring
    * make adding new node types easy
    * sentence nodes
        * different connection possibilities. hierarchical, sequential, codocument, complement
    * query node connected to all other nodes
        * one for each context-aware query sequence. one untransformed
    * make new config system for graph structuring options


* Fixes
    * fix max runtime counting
    * fix single run function
    * fix local loss viz


* before next experiment round:
    * remove legacy exception handling, todos
    * move utils out of the training folder
    * rename character embedders in glove embedder
    * touch up num params logging
    * clean name, without number for grouping
    * rename charcter embedder file
    * graph construction statistics on wandb
        * num nodes, num edges, num discarded examples
        * add network timing data to wandb


* house keeping:
    * ssh keygen for viz
    * move wandb folder out of HDE
    * get rid of the summariser/switch summariser distinction
        turn rel off by only using the global edge




Installs:
ENV_NAME=gnn_env
conda create --name ${ENV_NAME} python=3.7
y
conda activate ${ENV_NAME}

CUDA=cu102
TORCH=1.6.0
conda install pytorch==${TORCH} torchvision==0.7.0 cudatoolkit=10.2 -c pytorch
pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --user --no-cache-dir
pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --user --no-cache-dir
pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --user --no-cache-dir
pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --user --no-cache-dir
pip install torch-geometric --user
pip install transformers --user
conda install -c conda-forge nlp
# token only models do not need spacy
pip install -U spacy==2.1.3 --user
python -m spacy download en_core_web_sm
# NC not needed unless corefs are used as nodes
pip install neuralcoref --no-binary neuralcoref --user
# for vizualisation capabilities
conda install -c anaconda python-graphviz
# for wandb logging
pip install wandb


