Todo:
* change graph encoding to inherit Batch instead of Data
* bug in graph construction - word to token not getting every link
* switch super to explicit class in module system
* returning edges type-id issue
* create config save/load system
    * create configs for Longformer, Big Bird, HDE


* Graph embedder
     * query aware embeddings
     * make fine tuning the contextual embedder optional
     * edge feature encodings. an embedder for subtype info
     * more sophisticated attentive summarisation, possibly utilising sliding window att to pretransform a sequence
        before using self attentive pooling

* Graph construction
     * swap out spacy coref for something better
     * node filters to allow for word nodes be filtered by query words
     * decouple with spacy tokens
     * AMR
     * make type a param not class type. when special classes are created - they pass a rep of their class type to type
        * this allows for generic edges and nodes which can still be given distinct types/subtypes

* GNNs
    * configurable activations and regularisers
    * allow no message module in a graph layer, bypassing the prop call
    * add biases and reset params to all graph layers
    * bake in residual connections transformer style
    * create output models
        * span prediction
        * autodetect output model type based on data sample
    * make generic hierarchical layer switching module
        * basic is layer dependants + 1 layer agnostic
        * can be reused for task switching later
    * switch additive attention for dot-product

* config summary graphs for visualisation
    * graph construction summary graphs
        * can include embedding information
    * gnn layer switching summary graphs
    * gnn summary graph which doesn't include switching info. just layers, types, sizes. like cdn diagram
     * make fine tuning the contextual embedder optional

* render sparse adjacency matrices


* Make bert tokeniser cased
* add in returning edges for the directed edges

NLP Libs:
Spacy - ineffective
StanfordNLP python wrapper has no coref

