{
  "dataset": "wikihop",
  "model_name": "roberta",
  "embedded_dims": 20,
  "glove_tokens_code": "6B",
  "transformer_heads": 4,

  "model_class": "HDE",
  "gnn_class": "TransformerEdge",
  "use_gating": true,
  "use_transformer_block": false,
  "use_simple_hde": true,

  "layerwise_weight_sharing": true,
  "use_switch_summariser": false,
  "use_switch_coattention": false,
  "use_switch_gnn": false,
  "gnn_aggr": "mean",

  "use_global_edge_message": true,
  "scale_accumulated_gradients": true,

  "embedder_type": "bert",
  "bert_name": "roberta-base",
  "bert_fine_tune_layers": [],
  "bert_size": "tiny",

  "include_trans_gnn_edge_types": true,
  "include_trans_gnn_edges": true
}